{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e227ff8-43c0-4689-b533-0da4bcdb4e06",
   "metadata": {},
   "source": [
    "# SQLAlchemy – NoSQL (optional)\n",
    "\n",
    "This last course is optional and intended for those of you who have fully understood the entire SQL section. The topics will not be covered in depth, the goal is just to attract your attention and make you aware of their existence. The goal is to give yous some notions in case you are confronted with such subjects in the future, or that you wish to deepen them by yourself in order to perfect your mastery of databases with Python.\n",
    "\n",
    "## SQLAlchemy\n",
    "\n",
    "Unlike SQLite, SQLAlchemy is not a database engine or a DBMS, but a database access toolkit. More exactly, SQLAclhemy is known for a component called ORM : Object Relational Mapper, which is the most used one. What is it ? Python is an object-oriented language, and the SQLAlchemy’s ORM will map SQL queries results to objects, which are easierly and more powerfully manipulated by Python. SQLAlchemy is an interface between the database engine and Python, making transparent the manipulation of SQL queries while maintaining their effectiveness.\n",
    "\n",
    "Some of the classes used by SQLAlchemy are (you will intuitively know to what SQL entities they are linked) :\n",
    "\n",
    "* Base\n",
    "* Table\n",
    "* Column\n",
    "* ForeignKey\n",
    "* Integer\n",
    "* String\n",
    "* etc.\n",
    "\n",
    "### Simple : SQLAlchemy to connect to a database\n",
    "\n",
    "The simpler use of SQLAlchemy is just to declare an engine and use it to connect to an existing database, and refer to this connection with a connector. We could then send queries via this connector with methods like `pd.read_sql_query()` :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3092e275-1331-42bb-83b6-3bb4a51597b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "\n",
    "engine = create_engine(os.path.join('sqlite:///','data', 'european-soccer.sqlite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cc647a5-6284-49a1-a1b4-cbf8ff0793db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def request(query, engine=engine):\n",
    "    with engine.begin() as conn:\n",
    "        return pd.read_sql_query(text(query), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5229adb-3719-45e4-b682-952f85720af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id         name\n",
      "0       1      Belgium\n",
      "1    1729      England\n",
      "2    4769       France\n",
      "3    7809      Germany\n",
      "4   10257        Italy\n",
      "5   13274  Netherlands\n",
      "6   15722       Poland\n",
      "7   17642     Portugal\n",
      "8   19694     Scotland\n",
      "9   21518        Spain\n",
      "10  24558  Switzerland\n"
     ]
    }
   ],
   "source": [
    "print(request('SELECT * FROM Country'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b41bd53-7dd6-4dbb-94c7-0f8e66b72703",
   "metadata": {},
   "source": [
    "With SQLAchemy, you can create engine to connect to most of the DBMS : you will have the same interface to connect to a lot of different DBMS. For example, if MySQL runs on your computer, you can connect to a MySQL database as such :\n",
    "\n",
    "```Python\n",
    "################################################################\n",
    "# To connect to a MySQL database running local with SQLAlchemy #\n",
    "################################################################\n",
    "\n",
    "user = \"<user_name>\"\n",
    "password = \"<user_password>\"\n",
    "db_name = \"<database_name>\"\n",
    "port = 3306 # default port for MySQL but \n",
    "host = \"127.0.0.1\" # you can also try using \"localhost\" – if MySQL runs distant, \n",
    "                    # host will be the server address\n",
    "connection_infos = f\"mysql+mysqldb://{user}:{password}@{host}:{port}/{db_name}\"\n",
    "engine = create_engine(connection_infos)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2ed81a-61a0-4e96-a768-6e871a7de25d",
   "metadata": {},
   "source": [
    "### Advanced : SQLAlchemy models\n",
    "\n",
    "If we don’t want to use the SQLAlchemy interface to connect ot a database and not query it with SQL queries, we have to create a model. It will define the mapping between the database tables and queries results and the object defined and used in Python. \n",
    "\n",
    "A model is a class, inherited from the `Base()` class, which, as its name tells, models columns making the tables, and relationships between the tables, etc.\n",
    "\n",
    "Remember our `movies.db` ?\n",
    "\n",
    "Let’s list its tables and columns, as a refresher :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05d717c5-bad7-4161-9069-610b0202360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "######################################################\n",
    "# List tables and columns of a database (arg = path) #\n",
    "######################################################\n",
    "\n",
    "def explore_db(path: 'string'):\n",
    "    conn = sqlite3.connect(path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    list_table = '''\n",
    "    PRAGMA table_list;\n",
    "    '''\n",
    "    c.execute(list_table)\n",
    "    for row in c.fetchall():\n",
    "        table = row[1] # to improve readability\n",
    "    \n",
    "        # then get columns names\n",
    "        column_list = 'PRAGMA table_info(' + table +')'\n",
    "        print('\\n----- table ' + row[1] + ' columns -----\\n')\n",
    "        c.execute(column_list)\n",
    "        \n",
    "        # print columns names\n",
    "        for row in  c.fetchall():\n",
    "            column = row[1] # to improve readability\n",
    "            print(column)\n",
    "        \n",
    "        # finally print first lines of each table   \n",
    "        print('\\n table ' + table + ' first lines :\\n')\n",
    "        select_all = 'SELECT * FROM ' + table + ' LIMIT 5'\n",
    "        c.execute(select_all)\n",
    "        for row in  c.fetchall():\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "684305e0-b351-4ba0-a95a-0f896db50592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- table Credits columns -----\n",
      "\n",
      "Id\n",
      "Movie_id\n",
      "Direction\n",
      "Producer\n",
      "Studio\n",
      "Playscreen\n",
      "Cast\n",
      "Country\n",
      "\n",
      " table Credits first lines :\n",
      "\n",
      "(1, 3, '\"Big director\"', '\"Big producer\"', '\"Big studio\"', '\"Big screenwriter\"', '\"Big Actor 1, Big Actor 2, Other big actors\"', '\"Big country\"')\n",
      "(2, 1, '\"Unknown director\"', '\"Unknown producteur\"', '\"Unknown studio\"', '\"Unknown screenwriter\"', '\"Unknown actor 1, Unknown acteur 2, Other unknown actors\"', '\"Unknown country\"')\n",
      "(3, 2, '\"Small director\"', '\"Small producer\"', '\"Small studio\"', '\"Small screenwriter\"', '\"Small actor 1, Small actor 2, Small other actors\"', '\"Small country\"')\n",
      "(4, 5, '\"Acceptable director\"', '\"Acceptable producer\"', '\"Acceptable studio\"', '\"Acceptable screenwriter\"', '\"Acceptable actor 1, Acceptable actor 2, Other acceptable actors\"', '\"Acceptable country\"')\n",
      "(5, 4, '\"Incompetent director\"', '\"Incompetent producer\"', '\"Incompetent studio\"', ' \"Incompetent screenwriter\"', '\"Incompetente actor 1, Incompetent actor 2, Other incompetent actors\"', '\"Incompetent country\"')\n",
      "\n",
      "----- table sqlite_sequence columns -----\n",
      "\n",
      "name\n",
      "seq\n",
      "\n",
      " table sqlite_sequence first lines :\n",
      "\n",
      "('Movies', 5)\n",
      "('Credits', 5)\n",
      "\n",
      "----- table Movies columns -----\n",
      "\n",
      "Id\n",
      "Title\n",
      "Date\n",
      "Duration\n",
      "Budget\n",
      "First_week_viewers\n",
      "Votes\n",
      "\n",
      " table Movies first lines :\n",
      "\n",
      "(1, 'A good movie', '2024-12-04', 120, 2000000, 259023, 4.36)\n",
      "(2, 'Another good movie, slightly better', '2024-12-05', 110, 500000, 354352, 4.63)\n",
      "(3, 'A bad movie, but with some success', '1985-01-01', 84, 600000, 165904, 4.26)\n",
      "(4, 'A very bad movie', '2005-04-25', 93, 1000000, 235, 2.86)\n",
      "(5, 'A not so bad movie', '2019-03-23', 104, 1500000, 40334, 3.86)\n",
      "\n",
      "----- table sqlite_schema columns -----\n",
      "\n",
      "type\n",
      "name\n",
      "tbl_name\n",
      "rootpage\n",
      "sql\n",
      "\n",
      " table sqlite_schema first lines :\n",
      "\n",
      "('table', 'Movies', 'Movies', 2, 'CREATE TABLE Movies(\\n    Id INTEGER PRIMARY KEY AUTOINCREMENT UNIQUE,\\n    Title TEXT,\\n    Date TEXT,\\n    Duration INTEGER,\\n    Budget INTEGER,\\n    First_week_viewers INTEGER,\\n    Votes REAl\\n    )')\n",
      "('index', 'sqlite_autoindex_Movies_1', 'Movies', 3, None)\n",
      "('table', 'sqlite_sequence', 'sqlite_sequence', 4, 'CREATE TABLE sqlite_sequence(name,seq)')\n",
      "('table', 'Credits', 'Credits', 5, 'CREATE TABLE Credits(\\n    Id INTEGER PRIMARY KEY AUTOINCREMENT UNIQUE,\\n    Movie_id INTEGER NOT NULL,\\n    Direction TEXT,\\n    Producer TEXT,\\n    Studio TEXT,\\n    Playscreen TEXT,\\n    Cast TEXT,\\n    Country TEXT,\\n    FOREIGN KEY (Movie_id)\\n        REFERENCES Movies (Id)\\n)')\n",
      "('index', 'sqlite_autoindex_Credits_1', 'Credits', 6, None)\n",
      "\n",
      "----- table sqlite_temp_schema columns -----\n",
      "\n",
      "type\n",
      "name\n",
      "tbl_name\n",
      "rootpage\n",
      "sql\n",
      "\n",
      " table sqlite_temp_schema first lines :\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore_db('data/movies.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace9748-b9d7-48d3-a5c4-562e658b7eac",
   "metadata": {},
   "source": [
    "Nous avons donc deux tables :\n",
    "\n",
    "* Credits (5 colonnes, cf. ci-dessus)\n",
    "* Movies (5 colonnes, cf. ci-dessus)\n",
    "\n",
    "Maintenant que nous nous sommes rafraîchi la mémoire, connectons-nous à la base : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d35b856-dd94-4371-b121-9171d3660055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "\n",
    "engine = create_engine(os.path.join('sqlite:///','data', 'movies.db'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f796f999-23db-43ce-84e5-4feb5d757e62",
   "metadata": {},
   "source": [
    "Et créons le modèle suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a98d238-68d7-4a05-b62b-78355d7265db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Table, Column, ForeignKey, Integer, String, Float\n",
    "from sqlalchemy.orm import declarative_base\n",
    "\n",
    "Base = declarative_base() # créons la classe de base dont vont hériter\n",
    "                          # les classes que nous allons créer pour le modèle\n",
    "\n",
    "class Movies(Base):    # on instancie la classe modèle pour la table Movies\n",
    "    __tablename__ = 'Movies' \n",
    "    Id = Column(Integer, primary_key=True) # instances des colonnes de la table\n",
    "    Title = Column(String)\n",
    "    Date = Column(String)\n",
    "    Duration = Column(Integer)\n",
    "    Budget = Column(Integer)\n",
    "    First_week_viewers = Column(Integer)\n",
    "    Votes = Column(Float)\n",
    "    \n",
    "class Credits(Base):\n",
    "    __tablename__ = 'Credits'\n",
    "    Id = Column(Integer, primary_key=True)\n",
    "    Movie_id = Column(String, ForeignKey('Movies.Id')) # relation entre tables\n",
    "    Direction = Column(String)\n",
    "    Producer = Column(String)\n",
    "    Studio = Column(String)\n",
    "    Playscreen = Column(String)\n",
    "    Cast = Column(String)\n",
    "    Country = Column(String)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ecc19a-e5d1-4ef0-baa9-e26b1af38ce7",
   "metadata": {},
   "source": [
    "Now, the model is declared, connection to the base is established, let’s see how we make a request.\n",
    "\n",
    "To do that, we have to open a `Session` : it is a 'holding place' as described in the SQLAlchemy documentation, where  \n",
    "```\n",
    "it provides the interface where SELECT and other queries are made that will return and modify ORM-mapped objects.\n",
    "```\n",
    "(objects that we have instanciated and loaded)\n",
    "\n",
    "Once the `session` is instanciated, we can call the `.query` method, that we will chain with other methods to create a query.\n",
    "\n",
    "Here the query that select all the records of the `Movies` table :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a09a8055-d8b3-4e88-8942-de3ecb91cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import Session\n",
    "\n",
    "with Session(engine) as session:\n",
    "    results = session.query(Movies).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134999b0-f0f7-4dbc-a5bf-3be0ffe72ea4",
   "metadata": {},
   "source": [
    "To display the results, we have to simply iterate and check the columns we want to get :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd15635-beef-4c05-80f1-13dc9d0bc5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A good movie 4.36\n",
      "Another good movie, slightly better 4.63\n",
      "A bad movie, but with some success 4.26\n",
      "A very bad movie 2.86\n",
      "A not so bad movie 3.86\n"
     ]
    }
   ],
   "source": [
    "for result in results: \n",
    "    print(result.Title, result.Votes) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad40944-fb78-4615-be51-2f046cf4a86a",
   "metadata": {},
   "source": [
    "The method `.filter` is used to create conditions of selection :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16bfa690-9ba1-4d1f-b360-60f7467a317b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A good movie 4.36\n",
      "Another good movie, slightly better 4.63\n",
      "A bad movie, but with some success 4.26\n"
     ]
    }
   ],
   "source": [
    "with Session(engine) as session:\n",
    "    results = session.query(Movies).filter(Movies.Votes > 4.0).all()\n",
    "    for result in results: \n",
    "        print(result.Title, result.Votes) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af78155-8f7d-4ba6-99e4-4e4ee5a9a60a",
   "metadata": {},
   "source": [
    "Others methods to write requests :\n",
    "* `.group_by()`\n",
    "* `.count()`\n",
    "* `.order_by()`\n",
    "* `.join()`\n",
    "* etc.\n",
    "\n",
    "You can read the [query guide](https://docs.sqlalchemy.org/en/14/orm/queryguide.html) in the SQLAlchemy documentation.\n",
    "\n",
    "You may ask : isn’t it a bit complicated just to write a query ? It is a high-level approach that respond to specific problems (do not use SQL, OOP, agnostic of the DBMS, etc.). Writing SQL directly is more a low-level approach, which comes with its set of difficulties : lack of flexibility, written for a precise DBMS, no-OOP, etc.). \n",
    "\n",
    "As previously said, this is not an extensive lecture about SQLAlchemy, but the idea is to mention the existence of this library, in case you are working on a project that uses it or requires it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bbf8b2-7cab-4951-8c0e-241deb2518b0",
   "metadata": {},
   "source": [
    "## NoSQL\n",
    "\n",
    "### Limits of the relational model\n",
    "\n",
    "As we have learned, SQL was designed to query relational databases. This kind of database has numerous advantages :\n",
    "\n",
    "* relational model make easy the querying on relationships between data belongings to multiple tables\n",
    "* data are stored in a well structured manner : the structure of the data model and data type is defined before the actual manipulation of the data\n",
    "* structure brings constraints that garanties that storage is secure and robust (very low risk of error). You can’t delete or add feature and data that would brings incoherence in the dataset (delete a column that is a foreign key in another table, create a column with a datatype or default value that conclicts with already existing data or structure definition, etc.)\n",
    "* [ACID](https://en.wikipedia.org/wiki/ACID) compliant :\n",
    "    * Atomicity : a query is executed with success, or not at all (if some error occured during the exectution). For example you can’t start an UPDATE and stop it before it is fully processed with some data modified and other not. That prevents the apparition of inconsistancies.\n",
    "    * Consistancy : the dataset is valid before a query is processed, and valid once it has been processed. If you write new data in the dataset, it must be valid according to all defined rules of the model\n",
    "    * Isolation : when several users access to the database at the same time, the DBMS has to deal with concurrent queries (that write and read the same data at the same time). The isolation principle ensures that at the end the database is in the same state as if it would have been requested sequentially (one query after the other)\n",
    "    * Durability : long term storage is secure : commited data can’t be lost\n",
    "  The ACID principle allows the possibility to perform complex operations in one single query, like joins operation\n",
    "\n",
    "But these qualities can become defects in some cases :\n",
    "\n",
    "* the emphasis – and necessity – on the model and the predefined structure lengthens the development time of such databases\n",
    "* another difficulty due to this dependance to structure is that it can’t manage unstructured data or data whose characteristics are not known in advance\n",
    "* the implementation, management or administration of relational databases is monolithic : they are hard to scale horizontally, they are easier to upscale or scale vertically\n",
    "\n",
    "  We have here to present some terminology : \n",
    "    * horizontal scaling is the process where the capacity of treatment of a database is obtained by adding other servers or node managing the data\n",
    "    * upscaling or vertical scaling is the process where the capacity of treatment of a database is obtained by upscaling the capacity of the server managing the database (more memory, more computing power, more storage capacity, etc.) wich is more expansive, demanding, and you can’t upscale forever (there is a physical limit, max memory or CPU, etc.)\n",
    "\n",
    "  When a database gets bigger, we may want to divides the data in smaller entities :\n",
    "    * horizontal partitioning : the records (lines) belonging to the same table can be distributed between several tables. For example a customers table could be divided between several tables, each table gathering the cutomers of a specific city (one table for Marseille, one for Paris, etc.) each table having records with the same columns. It’s easier to make an horizontal scaling in this case : you can add servers that manage determined tables. The problems is that the schema become confused (several tables with same structured records) especially when you have to write data and control constraints (reading is far simpler to deal with)\n",
    "    * vertical partitioning : a table is splitted along its columns (\"rows splitting\" : rows get splitted). For example a table customers containing customers id (Firstname, Lastname, birthday…), adress, orders, could be divided between an  id table, an address table and an orders table\n",
    "    * sharding : it is similar to horizontal partitioning, but shards (partition) go beyond that. In horizontal partitioning, there is only one schema, sharding implies that rows are distributed between several tables, but that it occurs between several instances of the schema. Each shard is totally independant and can be heberged on different servers, datacenters, etc.\n",
    "\n",
    "This lead to the idea that whe data gets big, and really big, there is a need of flexibility in the database schema. The relational model reaches its limits.\n",
    "\n",
    "### NoSQL \n",
    "\n",
    "NoSQL means \"Not only SQL\", and not \"Not SQL\"! That rather refers to \"no relational model\". Exemple of NoSQL solutions (disclaimer, the categorization is not as strict as presented, it’s just examples to fix the idea) : \n",
    "* MongoDB, CouchBase (documents - more or less complex JSON - rather than rows)\n",
    "* Redis, Amazon DynamoDB (key-values)\n",
    "* Cassandra, Big Table, Accumulo (columns)\n",
    "* Amazon Neptune, Neo4j (graphs)\n",
    "\n",
    "NoSQL deals with the limits exposed just before :\n",
    "\n",
    "* NoSQL is flexible because *it just does not support* relationships between tables (simple!). So it can deal with unstructured data or data whose type is not well known (or totally unknown) before we build the database. The structures in NoSQL can be :\n",
    "    * an unstructured document (JSON, BSON, XML, etc.)\n",
    "    * a pair key-value object (particularly efficient for unique but complex values)\n",
    "    * a table (columns records rather than rows : efficient if queries only use few columns)\n",
    "    * graphs\n",
    "    * time series\n",
    "    * etc.\n",
    "* NoSQL do not follow a unique concept or schema, but it covers different types of non relational databases that correspond to different usecases\n",
    "* a NoSQL database can be built dynamically : schema has not to be defined before we begin to manage data. Moreover, documents belonging to the same collection can have different types (for example, the key-value documents do not need to have the same keys). Sometimes it is static, for example if we deal with a lot of columns oriented documents (tables).\n",
    "* dealing with unstructured data makes the sharding easier, and therefore the building of distributed databases and horizontal scaling far more easier. NoSQL engines are optimized to operate in highly distributed environment (datacenters scale)\n",
    "* in fact NoSQL database are generally used to build distributed database with large amount of data. On part of this process is the replication of shards of data from one node to others (replicas). That  is really useful when a lot of clients want to access to the data at the same time, to manage the load balance. But this operation takes time. This leads to a high risk of inconsistancy if one client access to a data in a replica that has not yet been updated (that’s more a problem of distributed databases than specifically NoSQL, but NoSQL are generally distributed databases).\n",
    "*  NoSQL is not specified to be ACID compliant, and there is no definition of a guaranteed simple way of performing a JOIN operation in one single request, for exemple (as there is no relation…). It does not mean that all NoSQL solutions are not ACID compliant (some of them are)\n",
    "*  Some NoSQL solutions can create in-memory database only (no physical storage of data in files)\n",
    "\n",
    "Moreover be careful. Know what you’re doing. Relational databases can also be dynamic, distributed, deal with JSON or exotic data structures. It’s just easier with NoSQL tools. On the contrary, as MongoDB is very easy to use, some has the reflex to use systematically a MongoDB databases, even in situations where they end-up building a NoSQL database that follows a relational model… that’s nonsense.\n",
    "\n",
    "### UnQLite\n",
    "\n",
    "UnQLite is an embedded NoSQL component comparable to SQLite (no need to install a third party server, lightweight - <1.8Mo). It was originally developped for Java, but a binding in Python can be installed with `pip`, along with Cython (for the binding). UnQLite is a serverless (like SQLite) JSON document store built on a fast key/value database. It has a specific scripting language to manage the JSON document store : Jx9. Nevertheless UnQLite is ACID compliant. It is a single file database (like SQLite), wirtten in C with no dependency (like SQLite), cross-platform (for the fileformat) and BSD licensed. UnQLite documentation is [here](https://unqlite-python.readthedocs.io/en/latest/).\n",
    "\n",
    "Cython is a language very close to Python, to which it adds support for some instructions in C/C++. It simplify the coding of extensions for Python.\n",
    "\n",
    "#### unqlite installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e195a976-c75e-4c13-86aa-f17eb0a1b7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Cython in /home/jean/.venv/courses/lib/python3.11/site-packages (3.0.11)\n",
      "Requirement already satisfied: unqlite in /home/jean/.venv/courses/lib/python3.11/site-packages (0.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install Cython unqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4b8da7-5137-4cbe-a8b3-83ed6ba92485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9504aff7-f889-45de-a3e9-23de79767d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unqlite import UnQLite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99dbdb3-4939-4b55-8fbd-bea84eda8001",
   "metadata": {},
   "source": [
    "#### Basic operations\n",
    "\n",
    "For a first try, let’s create a database which stands in memory only (just do not specify a filename) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6af65b06-09fa-49a4-8ccc-a6b1e1a65700",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = UnQLite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45b5533-6aa5-46b6-a3cf-e01743930969",
   "metadata": {},
   "source": [
    "To add an element to the database, you juste have to assign a value to a key in the database :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "342750b8-c127-4130-89c6-630490715ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database['key'] = 'value'\n",
    "'key' in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b9d7788-3ef3-4746-a9c8-f05973002547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.exists('key')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ca43b-4bac-4a21-842a-ae89d50474f8",
   "metadata": {},
   "source": [
    "The `.fetch()` method allows us to retrieve a value stored by calling its key :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d81cd563-23a4-489d-8081-8ead9ae7758d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'value'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.fetch('key')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a83be3-27cb-476a-a254-651f375c144b",
   "metadata": {},
   "source": [
    "Attention, in unqlite, everything – even text – is of the « byte string » type, a serie of values that not necessarily make sense to humans. In case of text, even if you believe you can read it, it is no guaranteed you have to decode it according to a standard of encoding : utf-8, or cp1252, ASCII… "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1e43aca-825e-4433-9f8d-4de755ca2fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'value'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.fetch('key').decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68836d49-a414-4565-898d-5ce0d90b0679",
   "metadata": {},
   "source": [
    "`.store()` is a method to add a key-value pair to the database :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b658234-6314-422f-8626-490b13d5d4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'value0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.store('key0', 'value0')\n",
    "database.fetch('key0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf2416-d89c-44c3-ae9c-7a1a446bef66",
   "metadata": {},
   "source": [
    "`.append()`, without surprise, appends a value to the data stored with the given key (if no data is associated to the key, it become just an equivalent to `.store()`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3a6ad6d-9416-4205-986d-5a4e03d15da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'value0value_appended'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.append('key0', '_value_appended')\n",
    "database.fetch('key0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e3fa30-13d4-4299-9212-cfcc865e3225",
   "metadata": {},
   "source": [
    "Another way to update the database is to pass a dictionnary to it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5579d34c-229b-458e-93b1-2af2dd3a80e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'value2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.update(\n",
    "    {'key1': 'value1',\n",
    "     'key2': 'value2'\n",
    "    }\n",
    ")\n",
    "\n",
    "database.fetch('key2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d40b09-01ee-4c1f-888c-225cd68fba1d",
   "metadata": {},
   "source": [
    "And, finally, you can drop a key-value pair with `.delete()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c73e6b8-1540-4683-8b5a-ccb7338d60d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.delete('key0')\n",
    "database.exists('key0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68553f4-2aa6-4cb3-95e9-c1502de5aa51",
   "metadata": {},
   "source": [
    "#### Keys - values\n",
    "\n",
    "NoSQL databases are often used to store data in the form of key - value pairs. Let’s create a database exemple that follows this schema :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "439ebc4d-e084-454c-b09b-c2d117675866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouvrir (ou créer) une base de données UnQLite\n",
    "users_db = unqlite.UnQLite()\n",
    "\n",
    "# Insérer des paires clé-valeur\n",
    "users_db['user_1'] = {\"name\": \"Alice\", \"age\": 25}\n",
    "users_db['user_2'] = {\"name\": \"Bob\", \"email\": \"bob@example.com\"}\n",
    "users_db['user_3'] = {\"name\": \"Charlie\", \"adress\": {\"city\": \"Paris\", \"zip_code\": 75001}}\n",
    "users_db['config'] = {\"theme\": \"dark\", \"lang\": \"fr\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a9e50-cba0-4b71-9484-41b1ef88d703",
   "metadata": {},
   "source": [
    "Get the keys of the base (as we could get the columns name in a relational database) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12feb088-37b9-4042-8763-4fe731585249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_1', 'user_2', 'user_3', 'config']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(users_db.keys()) # ATTENTION, we have to cast the result of the .keys() method to list to print it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5567bbc-1f51-49d5-8cdd-21d8b71066a2",
   "metadata": {},
   "source": [
    "We could also write :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6145ea6f-912f-4702-aa5f-27087d512a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_1\n",
      "user_2\n",
      "user_3\n",
      "config\n"
     ]
    }
   ],
   "source": [
    "for user in users_db.keys():\n",
    "    print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96a871-675c-4219-98b4-7fee6d75ffde",
   "metadata": {},
   "source": [
    "The result of the `.keys()` method is an iterable.\n",
    "\n",
    "What interests us are the values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd979497-c8d9-45fc-8642-5cc4f2fbc7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice', 'age': 25}\n",
      "{'name': 'Bob', 'email': 'bob@example.com'}\n",
      "{'name': 'Charlie', 'adress': {'city': 'Paris', 'zip_code': 75001}}\n",
      "{'theme': 'dark', 'lang': 'fr'}\n"
     ]
    }
   ],
   "source": [
    "for value in users_db.values():\n",
    "    print(value.decode('utf-8'))\n",
    "\n",
    "# or\n",
    "# list(users_db.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4858d49c-69d2-4133-bdc1-2a94be38c359",
   "metadata": {},
   "source": [
    "We have a `.keys()` and a `.values()` methods as for dictionnaries (and we also saw `.update()`before), do we have an `.items()` method too ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0617b17e-83be-4b48-baf6-45844f4df9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utilisateur_1: {'nom': 'Alice', 'age': 25}\n",
      "utilisateur_2: {'nom': 'Bob', 'email': 'bob@example.com'}\n",
      "utilisateur_3: {'nom': 'Charlie', 'adresse': {'ville': 'Paris', 'code_postal': 75001}}\n",
      "config: {'theme': 'dark', 'langue': 'fr'}\n"
     ]
    }
   ],
   "source": [
    "for key, value in db.items():\n",
    "    print(f\"{key}: {value.decode('utf-8')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b387364f-45dc-4309-a414-dc7f81ba1e6c",
   "metadata": {},
   "source": [
    "If the database behave like a dictionnary (or JSON), it is easy to select and filter datas. For example let’s build a students database and select the students with grades above 10 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b868e5-e376-4fa0-a2be-c16760e2166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# due to format pitfalls with unqlite, let’s create a decode_json function\n",
    "def decode_json(value: 'byte string') -> 'json':\n",
    "    return json.loads(value.decode('utf-8').replace(\"'\", \"\\\"\"))\n",
    "\n",
    "students_db = unqlite.UnQLite()\n",
    "\n",
    "# create the db\n",
    "students_db[\"student_1\"] = {\"name\": \"Alice\", \"grade\": 14}\n",
    "students_db[\"student_2\"] = {\"name\": \"Bob\", \"grade\": 9}\n",
    "students_db[\"student_3\"] = {\"name\": \"Charlie\", \"grade\": 16}\n",
    "students_db[\"student_4\"] = {\"name\": \"David\", \"grade\": 7}\n",
    "students_db[\"student_5\"] = {\"name\": \"Eve\", \"grade\": 12}\n",
    "\n",
    "# select students with grade > 10\n",
    "successful_students = [\n",
    "    decode_json(value) \n",
    "    for key, value in students_db.items() \n",
    "    if decode_json(value)[\"grade\"] > 10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b88aecd-b302-4d29-aca3-226585b26133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Alice', 'grade': 14},\n",
       " {'name': 'Charlie', 'grade': 16},\n",
       " {'name': 'Eve', 'grade': 12}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successful_students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fe2b00-9d12-4184-96d5-25c4e81d599b",
   "metadata": {},
   "source": [
    "#### Collections\n",
    "\n",
    "Besides of key-values data, another type often used in NoSQL are collections and documents. A *collection* is a set of documents which are JSON objects. Each document can have a different structure. It’s something very different and specific compared to relational databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33eba360-5556-425b-b772-87cb3bd93a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Users' collection documents :\n",
      "\n",
      "{'name': 'Alice', 'age': 25, '__id': 0}\n",
      "{'name': 'Bob', 'email': 'bob@example.com', '__id': 1}\n",
      "{'name': 'Charlie', 'adress': {'city': 'Paris', 'zip_code': 75001}, '__id': 2}\n",
      "{'name': 'David', 'hobbies': ['Music', 'Code'], '__id': 3}\n",
      "{'name': 'Eve', 'age': 30, 'email': 'eve@example.com', 'admin': True, '__id': 4}\n"
     ]
    }
   ],
   "source": [
    "users_db = unqlite.UnQLite()\n",
    "\n",
    "# connect to a collection (will be created if doesn’t exist yet - weird : you can instanciate something that doesn’t 'exist')\n",
    "collection = users_db.collection('users')\n",
    "if not collection.exists():\n",
    "    collection.create() \n",
    "    \n",
    "# add different documents (differents structures)\n",
    "collection.store([\n",
    "    {\"name\": \"Alice\", \"age\": 25},  # 2 fields : name, age\n",
    "    {\"name\": \"Bob\", \"email\": \"bob@example.com\"},  # 2 fields : name, email (no age)\n",
    "    {\"name\": \"Charlie\", \"adress\": {\"city\": \"Paris\", \"zip_code\": 75001}},  # nested object/JSON\n",
    "    {\"name\": \"David\", \"hobbies\": [\"Music\", \"Code\"]},  # 2 fields : name, list\n",
    "    {\"name\": \"Eve\", \"age\": 30, \"email\": \"eve@example.com\", \"admin\": True}  # 3 fields\n",
    "])\n",
    "\n",
    "# fetch all documents of the collection\n",
    "documents = collection.all()\n",
    "print(\"'Users' collection documents :\\n\")\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e5e50b-16b4-4876-a5cc-8bdc899a6b21",
   "metadata": {},
   "source": [
    "Question : Python already manage dictionnaries or JSON. What’s the advantage of a database engine here ? As we have already said multiple times, database management systems offers security, robustness and ease in the data storage process. For example, we will present in the two sections below some mechanisms or tools that help to achieve these goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad372b-0e43-429a-b736-cdb8451d72e1",
   "metadata": {},
   "source": [
    "#### Cursor\n",
    "\n",
    "We have used cursor with SQLite, but we did not explain why there is a cursor and why we use it. We presented cursors as read heads that moves through the database, as We move them in the database to where we want to perform our operations (read, write, get informations…). What’s the point with this method ? We have to keep in sight that a cursor is a mean to access to data sequentially, which has several advantages :\n",
    "\n",
    "* saves memory : we do not load all data in memory at once\n",
    "* preserves performance : in (very) large databases, it is completely inefficient to retrieve all elements stored\n",
    "* fine grained control : we can stop browsing data at any time, avoiding the loading of the remaining data into memory\n",
    "\n",
    "In a previous example we have used a method like `.items()` to retrieve key-value pairs, but it loads all the data in memory which is, for the reasons mentionned, inefficient.\n",
    "\n",
    "We will use a cursor instead, which will allow us to browse the data gradually, without loading everything. When there are many entries, we will avoid slowdowns in processing. In addition, it will allow us to add stopping conditions (e.g. stopping after a certain number of results). You can consider cursors as iterators, particularly efficient with large amount of key-value pairs data.\n",
    "\n",
    "Let’s see how cursors works with our exemple database `students_db` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "723332aa-f006-4b2d-aa8a-5ee59c6ceab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key of the first element : student_1\n",
      "\n",
      "value of the first element: {'name': 'Alice', 'grade': 14}\n",
      "\n",
      "key of the next element : student_2\n",
      "\n",
      "key of the last element : student_5\n",
      "\n",
      "key of the previous element : student_4\n",
      "\n",
      "key of the element pointed after a reset : student_1\n",
      "\n",
      "key of the element seeked (student_3) : student_3\n",
      "\n",
      "iteration from the (student_3) to the (student_4) elements:\n",
      " [('student_3', {'name': 'Charlie', 'grade': 16}), ('student_4', {'name': 'David', 'grade': 7})]\n"
     ]
    }
   ],
   "source": [
    "# it is recommanded to use .cursor() to define a context\n",
    "with students_db.cursor() as cursor:\n",
    "\n",
    "    # .first() method is used to place the cursor on the first element\n",
    "    cursor.first()\n",
    "\n",
    "    # .key() method returns the key of the element the cursor is pointing to\n",
    "    k = cursor.key()\n",
    "    print('key of the first element :', k)\n",
    "\n",
    "    # .value() method returns the value of the element the cursor is pointing to\n",
    "    v = cursor.value()\n",
    "    print('\\nvalue of the first element:', decode_json(v))\n",
    "\n",
    "    # .next_entry() method move the cursor to next element in the database\n",
    "    cursor.next_entry()\n",
    "    k = cursor.key()\n",
    "    print('\\nkey of the next element :', k)    \n",
    "\n",
    "    # .last() method move the cursor to the last element in the database\n",
    "    cursor.last()\n",
    "    k = cursor.key()\n",
    "    print('\\nkey of the last element :', k)\n",
    "\n",
    "    # .previous_entry() method move the cursor to previous element in the database\n",
    "    cursor.previous_entry()\n",
    "    k = cursor.key()\n",
    "    print('\\nkey of the previous element :', k)\n",
    "    \n",
    "    # .reset() method move the cursor to previous element in the database\n",
    "    cursor.reset()\n",
    "    k = cursor.key()\n",
    "    print('\\nkey of the element pointed after a reset :', k)\n",
    "\n",
    "    # .seek(key_seeked) method move the cursor to the element with key_seeked key\n",
    "    cursor.seek('student_3')\n",
    "    k = cursor.key()\n",
    "    print('\\nkey of the element seeked (student_3) :', k)\n",
    "\n",
    "    # .fetch_until(stop_key) method iterate from the current element to the element with stop_key key\n",
    "    it = [(k, decode_json(v)) for k, v in cursor.fetch_until('student_4')]\n",
    "    print('\\niteration from the (student_3) to the (student_4) elements:\\n', it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13cd63-f98f-4cf2-bf36-c507255820a2",
   "metadata": {},
   "source": [
    "See the [doc](https://unqlite-python.readthedocs.io/en/latest/api.html) for others methods.\n",
    "\n",
    "Now let’s select the students with grades above 10 using a cursor :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d32e1253-c305-4093-809f-1d1280a2e43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice - Note : 14\n",
      "Charlie - Note : 16\n",
      "Eve - Note : 12\n"
     ]
    }
   ],
   "source": [
    "with students_db.cursor() as cursor:\n",
    "    while True:\n",
    "        # get the value of the current cursor\n",
    "        student = decode_json(cursor.value())\n",
    "    \n",
    "        # check if grade > 10\n",
    "        if student['grade'] > 10:\n",
    "            print(f\"{student['name']} - Note : {student['grade']}\")\n",
    "    \n",
    "        # go to next record\n",
    "        cursor.next_entry()\n",
    "        if not cursor.is_valid():  # return False if we go past the last element (invalid position)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44422cd-8967-4f6c-befe-2d37062b249f",
   "metadata": {},
   "source": [
    "#### Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d8bd5-75df-473a-a613-55acfe5d8419",
   "metadata": {},
   "source": [
    "We never talked about the concept of transaction although it is important in database management.\n",
    "\n",
    "A database transaction is an « atomic operation » (or « unit of work », see this [wikipedia’s article](https://en.wikipedia.org/wiki/Unit_of_work)) on a database : any operation – as little it can be – which can affect the database. A transaction must be defined and implemented in a way that it can recover when errors occur to preserve the database integrity. Another concern is when several operations are asked at the same time (concurrency). This lead to concepts of isolation, consistency, atomicity… and you recognise the ACID properties mentioned above.\n",
    "\n",
    "ACID is important even in the NoSQL world, because large and distributed databases, precisely because of their size and distributed design, are more susceptible to error in the event of concurrent access. \n",
    "\n",
    "One way to view transactions from an operational perspective is the example of double-entry accounting. These operations/transactions are designed in a way that makes them at the same time a means of controlling their own validity : a debit transaction on one account must be offset by a credit transaction on another account. If this is not the case, the transaction is cancelled.\n",
    "\n",
    "* Debit 100€ to a supplier account\n",
    "* Credit 100€ to checking account\n",
    "\n",
    "UnQLite for example, offers a system of transaction : you can define a context for a transaction (recommanded), when this transaction start, what instructions it is made of, and – it is essential – have a method to cancel it (`.rollback()`) if something went wrong (error raised, condition not respected, etc.).\n",
    "\n",
    "IMPORTANT : this transaction mecanism works only on databases stored on files (no effects on memory-only).\n",
    "\n",
    "Imagine we want to add a new record to a collection, but something goes wrong during the recording operation, so we cancel it :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "308b82bd-0e74-4013-a9bf-0d55f1cc3c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur détectée : Some error occurs during the recording process!\n",
      "rollback done\n",
      "\n",
      "Documents in the collection (after the rollback) :\n",
      "{'name': 'Alice', 'age': 25, '__id': 0}\n",
      "{'name': 'Bob', 'email': 'bob@example.com', '__id': 1}\n",
      "{'name': 'Charlie', 'adress': {'city': 'Paris', 'zip_code': 75001}, '__id': 2}\n",
      "{'name': 'David', 'hobbies': ['Music', 'Code'], '__id': 3}\n",
      "{'name': 'Eve', 'age': 30, 'email': 'eve@example.com', 'admin': True, '__id': 4}\n"
     ]
    }
   ],
   "source": [
    "transactions_db = unqlite.UnQLite('transactions_demo.db') # transactions only work for db stored in file\n",
    "\n",
    "# Let’s create a collection base\n",
    "\n",
    "collection = transactions_db.collection('transactions')\n",
    "\n",
    "if not collection.exists():\n",
    "    collection.create() \n",
    "\n",
    "collection.store([\n",
    "    {\"name\": \"Alice\", \"age\": 25},\n",
    "    {\"name\": \"Bob\", \"email\": \"bob@example.com\"},\n",
    "    {\"name\": \"Charlie\", \"adress\": {\"city\": \"Paris\", \"zip_code\": 75001}},\n",
    "    {\"name\": \"David\", \"hobbies\": [\"Music\", \"Code\"]},\n",
    "    {\"name\": \"Eve\", \"age\": 30, \"email\": \"eve@example.com\", \"admin\": True}\n",
    "])\n",
    "transactions_db.commit() # don’t forget to commit to file\n",
    "\n",
    "# Now, let’s add a record, securing the process with a transaction :\n",
    "    \n",
    "with transactions_db.transaction():\n",
    "    try:\n",
    "        # start a transaction\n",
    "        transactions_db.begin()\n",
    "        \n",
    "        # add a record\n",
    "        collection.store([\n",
    "            {\"name\": \"John\", \"age\": 25}\n",
    "        ])\n",
    "        \n",
    "        # Raise an error ! (simulated here, of course)\n",
    "        raise ValueError(\"Some error occurs during the recording process!\")\n",
    "    \n",
    "        # commit the insertion of a new record\n",
    "        transactions_db.commit()\n",
    "        \n",
    "    # if an error occured, rollback the transaction :\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur détectée : {e}\")\n",
    "        \n",
    "        transactions_db.rollback()\n",
    "        print('rollback done')\n",
    "    \n",
    "    # Let’s see if the record was inserted ?\n",
    "    documents = collection.all()\n",
    "    print(\"\\nDocuments in the collection (after the rollback) :\")\n",
    "    for doc in documents:\n",
    "        print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066ab3c-3065-4c66-9139-b23dd5cfff17",
   "metadata": {},
   "source": [
    "No new element where added !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0757e9ff-2613-45f6-9bbb-f16e854ebb08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
